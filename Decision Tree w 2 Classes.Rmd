---
title: "2 Class Model"
author: "Tilina Alzaben"
date: "2022-07-12"
output: html_document
---

```{r}
set.seed(42)
```

```{r}
#IMPORT LIBRARIES
library(readr)
library(ggplot2)
library(dplyr)
library(knitr)
library(lubridate)
library(tree)
library(rpart)
library(rpart.plot)
library(mlr)
library(caret)
library(randomForest)
library(tree)
```

```{r}
#Read in the Client and Loan Data
client <- read_csv("C:/Users/tilin/Desktop/BetterFi/Copy of DataLab-clientdata-anon.csv")
loan <- read_csv("C:/Users/tilin/Desktop/BetterFi/Copy of DataLab-loandata-anon.csv")
loan2 <- read_csv("C:/Users/tilin/Downloads/LOAN-DATA-070122.csv")
```

```{r}
#Cleaning Client Data
clientClean <- client %>% 
  mutate(streetcity = case_when(streetcity == 'Traciy City' | streetcity == 'TRACY CITY' ~ 'Tracy City', 
                                streetcity == 'TULLAHOMA' ~ 'Tullahoma',
                                TRUE ~ streetcity)) %>%  
  mutate(employer = ifelse(is.na(employer), "UNEMPLOYED", client$employer)) %>% 
  mutate(incomeamt = case_when(incomefreq == 'MO' || incomefreq == 'mo' ~ incomeamt, 
                               incomefreq == 'biwk' || incomefreq == 'BI' ~ incomeamt * 2, 
                               incomefreq == 'WE' ~ incomeamt * 4)) %>% 
  mutate(residenceyear= floor(as.numeric(residenceperiod)/12)) %>% 
  mutate(carsinhh = ifelse(is.na(carsinhh), 0, carsinhh)) %>% 
  mutate(County = ifelse(is.na(County), 'Suffolk County', client$County)) %>%
  mutate(totalExpense = rowSums(client[,c(54, 55, 56, 57, 59)], na.rm = TRUE)) %>% 
  select(custID,
         streetcity, 
         streetzip, 
         County, 
         income_source, 
         employer,
         incomeamt, 
         annualincome, 
         incomelevel, 
         totalExpense, 
         carsinhh, 
         residenceyear, 
         referenceperson)
clientClean %>% View
```

```{r}
#Cleaning Loan Data
loanClean <- loan %>% 
  mutate(status_code = case_when(is.na(status_code) ~ "active", 
                                 status_code == 'pif_refinanced' ~ 'pif', 
                                 TRUE ~ loan$status_code)) %>% 
  select(primary_borrower_name, status_code, purpose, amount_approved, full_identifier) 

loan2Clean <- loan2 %>% 
  select(payment_periods, primary_borrower_name, loan_identifier) %>% 
  mutate(payment_periods = gsub("mo","", as.character(payment_periods))) 

loanData <- merge(loanClean, loan2Clean, by.x = 'full_identifier', by.y = 'loan_identifier') %>% 
  mutate(monthlyPayment = round(amount_approved/as.numeric(payment_periods), 2))

loanData <- loanData[-7]
loanData %>% View
```

```{r}
#Creating One Data set
df <- merge(clientClean, loanData, by.x = 'custID', by.y = 'primary_borrower_name.x')
df <- df[df$status_code != 'active',] 
df <- df[-c(1, 14)]
df %>% View
```

```{r}
#Turning Categorical Variables into Factors
cat <- c('streetcity', 'streetzip', 'County', 'income_source', 'employer', 'referenceperson', 
         'incomelevel', 'status_code', 'purpose', 'carsinhh', 'payment_periods')

for(x in cat) {
    df[, x] <- as.factor(df[, x])
}

str(df)
```

```{r}
#Training/Testing/Validation Data Sets
set.seed(100)
trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)

train <- df[trainRowNumbers,]
test <- df[-trainRowNumbers,]
dim(train); dim(test)
```

```{r}
## Feature Selection
fit <- rpart(status_code ~ ., 
             data = df)

data.frame(imp = fit$variable.importance)
```

```{r}
#CLASSIFICATION Decision Tree

#BASE MODEL - ALL VARIABLES
model0 = tree(status_code ~ ., 
             na.action = na.pass, 
             method = "class", 
             split = c("deviance", "gini"),
             data = train)
summary(model0)

#TRAIN ACCURACY
model0_train_pred = predict(model0, train, type = "class")
table(predicted = model0_train_pred, actual = train$status_code)

#TEST ACCURACY
model0_test_pred = predict(model0, test, type = "class")
table(predicted = model0_test_pred, actual = test$status_code)
```

```{r}
#RUNNING A BASE CLASS MODEL
d.tree = rpart(status_code ~ ., 
               data=train, 
               method = 'class')

#BASE MODEL PRECISION
predicted_values <- predict(d.tree, test, type = 'class')
accuracy(test$status_code, predicted_values)

#CREATING MODEL TASK (CLASS)
task <- makeClassifTask(data = df, target = "status_code")
tree <- makeLearner("classif.rpart")

#SELECTING PARAMETERS TO HYPTERTUNE
treeParamSpace <- makeParamSet(
  makeIntegerParam("minsplit", lower = 5, upper = 20),
  makeIntegerParam("minbucket", lower = 3, upper = 10),
  makeNumericParam("cp", lower = 0.01, upper = 0.1),
  makeIntegerParam("maxdepth", lower = 3, upper = 10)
)

#GRID SEARCH TO SELECT BEST PARAMETERS
randSearch <- makeTuneControlRandom(maxit = 200)
cvForTuning <- makeResampleDesc("CV", iters = 5)

tunedTreePars <- tuneParams(tree, 
                            task = task,
                            resampling = cvForTuning,
                            par.set = treeParamSpace,
                            control = randSearch)

tunedTreePars
```

```{r}
#BASE MODEL WITH HYPERTUNED PARAMETERS
set.seed(42)
model <- rpart(status_code ~ ., 
               data = train, 
               method = "class", 
               control = rpart.control(maxdepth = 5, 
                                       minbucket = 3, 
                                       minsplit = 8, 
                                       cp = 0.0202), 
               na.action = na.pass)
summary(model)
rpart.plot(model,extra=2, cex=0.6)

accuracy <- c()
for(i in 1:50) {
  
  trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)
  
  train <- df[trainRowNumbers,]
  test <- df[-trainRowNumbers,]
  
  
  pred <- predict(model, test, type = 'class')
  accuracy[i] <- accuracy(test$status_code, pred)
  i = i + 1
}

mean(accuracy)
```
```{r}
#MODEL 1
set.seed(100)
model1 = tree(status_code ~ payment_periods + employer + amount_approved + streetcity + annualincome + residenceyear + 
                totalExpense + income_source,  
             na.action = na.pass, 
             method = "class", 
             split = c("deviance", "gini"),
             data = train)
summary(model1)

accuracy <- c()
#Cross Validation For Splitting Training and Testing
for(i in 1:50) {

  trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)
  
  train <- df[trainRowNumbers,]
  test <- df[-trainRowNumbers,]
  
  model1_test_pred = predict(model1, test, type = "class")
  matrix <- table(predicted = model1_test_pred, actual = test$status_code)
  accuracy[i] <- sum(diag(matrix))/sum(matrix)
  
  i = i + 1
}

mean(accuracy)
```

```{r}
#BASE MODEL - ALL VARIABLES
set.seed(100)

model0 <- tree(status_code ~ ., 
             na.action = na.pass, 
             method = "class", 
             split = c("deviance", "gini"),
             data = train)
summary(model0)

accuracy <- c()
#Cross Validation For Splitting Training and Testing
for(i in 1:50) {

  trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)
  
  train <- df[trainRowNumbers,]
  test <- df[-trainRowNumbers,]
  
  #TEST ACCURACY
  model0_test_pred <- predict(model0, test, type = "class")
  matrix <- table(predicted = model0_test_pred, actual = test$status_code)
  accuracy[i] <- sum(diag(matrix))/sum(matrix)
  
  i = i + 1
  
}

mean(accuracy)
```
```{r}
#PRUNED DECISION TREE
prune0 = prune.misclass(model0, best = 6)
summary(prune0)

plot(prune0)
text(prune0, pretty = 0)
title(main = "Pruned Classification Tree")
```

```{r}
#MODEL 2
set.seed(100)
model2 = tree(status_code ~ payment_periods + purpose + incomeamt + referenceperson + streetzip,  
             na.action = na.pass, 
             method = "class", 
             split = c("deviance", "gini"),
             data = train)
summary(model2)

accuracy <- c()
#Cross Validation For Splitting Training and Testing
for(i in 1:50) {

  trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)
  
  train <- df[trainRowNumbers,]
  test <- df[-trainRowNumbers,]
  
  model2_test_pred = predict(model2, test, type = "class")
  matrix <- table(predicted = model2_test_pred, actual = test$status_code)
  accuracy[i] <- sum(diag(matrix))/sum(matrix)
  
  i = i + 1
}

mean(accuracy)
```
```{r}
#MODEL 2 VISUALIZATION
prune0 = prune.misclass(model2, best = 6)
summary(prune0)

plot(model2)
text(model2, pretty = 0)
title(main = "Pruned Classification Tree")
```


```{r}
#MODEL 3 - VARIABLES SELECTED BY THE GROUP
set.seed(100)
model3 = tree(status_code ~ payment_periods + amount_approved + incomeamt + streetcity + employer + referenceperson + purpose,  
             na.action = na.pass, 
             method = "class", 
             split = c("deviance", "gini"),
             data = train)
summary(model3)

accuracy <- c()
#Cross Validation For Splitting Training and Testing
for(i in 1:50) {

  trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)
  
  train <- df[trainRowNumbers,]
  test <- df[-trainRowNumbers,]
  
  model3_test_pred = predict(model3, test, type = "class")
  matrix <- table(predicted = model3_test_pred, actual = test$status_code)
  accuracy[i] <- sum(diag(matrix))/sum(matrix)
  
  i = i + 1
}

mean(accuracy)
```

```{r}
#MODEL 3 VISUALIZATION
prune0 = prune.misclass(model3, best = 6)
summary(prune0)

plot(model3)
text(model3, pretty = 0)
title(main = "Pruned Classification Tree")
```
```{r}
#MODEL 4
set.seed(100)
model4 = tree(status_code ~ streetzip + income_source + annualincome + payment_periods + amount_approved,  
             na.action = na.pass, 
             method = "class", 
             split = c("deviance", "gini"),
             data = train)
summary(model4)

accuracy <- c()
#Cross Validation For Splitting Training and Testing
for(i in 1:50) {

  trainRowNumbers <- createDataPartition(df$status_code, p=0.7, list=FALSE)
  
  train <- df[trainRowNumbers,]
  test <- df[-trainRowNumbers,]
  
  model4_test_pred = predict(model4, test, type = "class")
  matrix <- table(predicted = model4_test_pred, actual = test$status_code)
  accuracy[i] <- sum(diag(matrix))/sum(matrix)
  
  i = i + 1
}

mean(accuracy)
```





